{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. BFS路线搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUANGZHOU✈️-> WUHAN✈️-> BEIJING\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BEIJING, CHANGCHUN, URUMCHI, WUHAN, GUNAGHZOU, SHENZHEN, BANGKOK, SHANGHAI, NEWYORK = \"\"\"\n",
    "BEIJING CHANGCHUN URUMCHI WUHAN GUANGZHOU SHENZHEN BANGKOK SHANGHAI NEWYORK\n",
    "\"\"\".split()\n",
    "\n",
    "connection_2 = {\n",
    "    0: [1, 5], \n",
    "    1: [0, 2], \n",
    "    2: [1, 3], \n",
    "    3: [2, 4], \n",
    "    4: [3],\n",
    "    5: [0, 6], \n",
    "    6: [5, 7],\n",
    "    7: [6]\n",
    "}\n",
    "\n",
    "connection = {\n",
    "\tCHANGCHUN: [BEIJING],\n",
    "\tURUMCHI: [BEIJING], \n",
    "\tBEIJING: [URUMCHI, CHANGCHUN,WUHAN, SHENZHEN, NEWYORK],\n",
    "\tNEWYORK: [BEIJING, SHANGHAI],\n",
    "    SHANGHAI: [NEWYORK, WUHAN],\n",
    "    WUHAN: [SHANGHAI, BEIJING, GUNAGHZOU],\n",
    "    GUNAGHZOU: [WUHAN, BANGKOK],\n",
    "    SHENZHEN: [WUHAN, BANGKOK],\n",
    "    BANGKOK: [SHENZHEN, GUNAGHZOU]\n",
    "}\n",
    "\n",
    "def nagivator(start, destination, connection_graph):\n",
    "\tpathes = [[start]]\n",
    "\tseen = set()\n",
    "\n",
    "\twhile pathes:\n",
    "\t\tpath = pathes.pop(0)\n",
    "\t\tfrontier = path[-1]\n",
    "\n",
    "\t\tif frontier is seen:\n",
    "\t\t\tcontinue\n",
    "\t\tseen.add(frontier)\n",
    "\t\tsuccessors = connection_graph[frontier]\n",
    "\n",
    "\t\tfor s in successors:\n",
    "\t\t\tif s == destination:\n",
    "\t\t\t\tpath.append(s)\n",
    "\t\t\t\treturn path\n",
    "\t\t\telse:\n",
    "\t\t\t\tpathes.append(path+[s])\n",
    "\t\tpathes = sorted(pathes, key = len)\n",
    "\n",
    "\treturn []\n",
    "\n",
    "print('✈️-> '.join(nagivator(GUNAGHZOU, BEIJING, connection)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 文本自动匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r [['noun_phrase', 'verb_phrase']]\n",
      "rele ['noun_phrase', 'verb_phrase']\n",
      "r [['Article', 'Adj*', 'noun']]\n",
      "rele ['Article', 'Adj*', 'noun']\n",
      "r [['一个'], ['这个']]\n",
      "rele ['这个']\n",
      "r [['null'], ['Adj', 'Adj*']]\n",
      "rele ['null']\n",
      "r [['女人'], ['篮球'], ['桌子'], ['小猫']]\n",
      "rele ['女人']\n",
      "r [['verb', 'noun_phrase']]\n",
      "rele ['verb', 'noun_phrase']\n",
      "r [['看着'], ['坐在'], ['听着'], ['看见']]\n",
      "rele ['坐在']\n",
      "r [['Article', 'Adj*', 'noun']]\n",
      "rele ['Article', 'Adj*', 'noun']\n",
      "r [['一个'], ['这个']]\n",
      "rele ['这个']\n",
      "r [['null'], ['Adj', 'Adj*']]\n",
      "rele ['Adj', 'Adj*']\n",
      "r [['蓝色的'], ['好看的'], ['小小的']]\n",
      "rele ['蓝色的']\n",
      "r [['null'], ['Adj', 'Adj*']]\n",
      "rele ['null']\n",
      "r [['女人'], ['篮球'], ['桌子'], ['小猫']]\n",
      "rele ['小猫']\n",
      "这个女人坐在这个蓝色的小猫\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "grammar = \"\"\"\n",
    "sentence => noun_phrase verb_phrase \n",
    "noun_phrase => Article Adj* noun\n",
    "Adj* => null | Adj Adj*\n",
    "verb_phrase => verb noun_phrase\n",
    "Article =>  一个 | 这个\n",
    "noun =>   女人 |  篮球 | 桌子 | 小猫\n",
    "verb => 看着   |  坐在 |  听着 | 看见\n",
    "Adj =>   蓝色的 |  好看的 | 小小的\n",
    "\"\"\"\n",
    "\n",
    "def parse_grammar(grammar_str, sep = '=>'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        target, rules = line.split(sep)\n",
    "        grammar[target.strip()] = [r.split() for r in rules.split('|')]\n",
    "    return grammar\n",
    "\n",
    "def gene(grammar_parsed, target = 'sentence'):\n",
    "    if target not in grammar_parsed:\n",
    "        return target\n",
    "    r = grammar_parsed[target]\n",
    "    print('r',r)\n",
    "    rule = random.choice(r)\n",
    "    print('rele',rule)\n",
    "    return ''.join(gene(grammar_parsed, target=r) for r in rule if r != 'null')\n",
    "\n",
    "\n",
    "g = parse_grammar(grammar)\n",
    "\n",
    "print(gene(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Pattern Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image you will get apple soon\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def is_variable(pat):\n",
    "\treturn pat.startswith('?') and all(s.isalpha() for s in pat[1:])\n",
    "\n",
    "def pat_match(pattern, saying):\n",
    "\tif not pattern or not saying:\n",
    "\t\treturn []\n",
    "\tif is_variable(pattern[0]):\n",
    "\t\treturn [(pattern[0], saying[0])] + pat_match(pattern[1:], saying[1:])\n",
    "\telif pattern[0] != saying[0]:\n",
    "\t\t\treturn False\n",
    "\telse:\n",
    "\t\treturn pat_match(pattern[1:], saying[1:])\n",
    "\n",
    "\n",
    "def pat_to_dict(patterns):\n",
    "\treturn {k:v for k,v in patterns}\n",
    "\n",
    "def substitute(rule, parsed_rules):\n",
    "\tif not rule:return []\n",
    "\t# dict.get(key, default = None):如果key不存在则返回默认值\n",
    "\n",
    "\treturn [parsed_rules.get(rule[0], rule[0])] + substitute(rule[1:],parsed_rules)\n",
    "\n",
    "\n",
    "defined_patterns = {\n",
    "    \"I need ?X\": [\"Image you will get ?X soon\", \"Why do you need ?X ?\"], \n",
    "    \"My ?X told me something\": [\"Talk about more about your ?X\", \"How do you think about your ?X ?\"]\n",
    "}\n",
    "\n",
    "def get_response(saying, rules = defined_patterns):\n",
    "\tfor pattern in rules.keys():\n",
    "\t\tpat = pat_match(pattern.split(),saying.split())\n",
    "\t\t\n",
    "\t\tif pat:\n",
    "\t\t\tresponse_pattern = random.choice(rules[pattern]) \n",
    "\t\t\tresponce = substitute(response_pattern.split(),pat_to_dict(pat))\n",
    "\t\t\treturn ' '.join(responce)\n",
    "\treturn \"sorry, I don't know!\"\n",
    "\n",
    "\n",
    "print(get_response('I need apple'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Segment Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I already knew you were a beautiful and sunny girl .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def is_variable(pat):\n",
    "\treturn pat.startswith('?') and all(s.isalpha() for s in pat[1:])\n",
    "\n",
    "# 判断是否为‘？*‘\n",
    "def is_pattern_segment(pattern):\n",
    "\treturn pattern.startswith('?*') and all(s.isalpha() for s in pattern[2:])\n",
    "\n",
    "def is_match(rest, saying):\n",
    "    if not rest and not saying:\n",
    "        return True\n",
    "    if not all(a.isalpha() for a in rest[0]):\n",
    "        return True\n",
    "    if rest[0] != saying[0]:\n",
    "        return False\n",
    "    return is_match(rest[1:], saying[1:])\n",
    "    \n",
    "def segment_match(pattern,saying):\n",
    "\tseg_pat, rest = pattern[0], pattern[1:]\n",
    "\tseg_pat =seg_pat.replace('?*','?')\n",
    "\n",
    "\tif not rest: \n",
    "\t\treturn (seg_pat, saying),len(saying)\n",
    "\n",
    "\tfor i,token in enumerate(saying):\n",
    "\t\tif rest[0] == token and is_match(rest[1:], saying[(i + 1):]):\n",
    "\t\t\tprint('is_match',is_match(rest[1:], saying[(i + 1):]))\n",
    "\t\t\treturn (seg_pat, saying[:i]),i\n",
    "\n",
    "\treturn (seg_pat, None),0\n",
    "\n",
    "\n",
    "fail = [True,None]\n",
    "def pat_match_with_seg(pattern, saying):\n",
    "\tif not pattern or not saying:\n",
    "\t\treturn []\n",
    "\tpat = pattern[0]\n",
    "\n",
    "\tif is_variable(pat):\n",
    "\t\treturn [pat, saying[0]] + pat_match_with_seg(pattern[1:],saying[1:])\n",
    "\telif is_pattern_segment(pat):\n",
    "\t\tmatch, index = segment_match(pattern,saying)\n",
    "\t\treturn [match] + pat_match_with_seg(pattern[1:], saying[index:])\n",
    "\telif pat == saying[0]:\n",
    "\t\treturn pat_match_with_seg(pattern[1:],saying[1:])\n",
    "\telse:\n",
    "\t\treturn fail\n",
    "\n",
    "def pat_to_dict(patterns):\n",
    "    return {k: ' '.join(v) if isinstance(v, list) else v for k, v in patterns}\n",
    "\n",
    "def substitute(rule, parsed_rules):\n",
    "    if not rule: return []\n",
    "    \n",
    "    return [parsed_rules.get(rule[0], rule[0])] + substitute(rule[1:], parsed_rules)\n",
    "\n",
    "rules = {\n",
    "    \"?*X hello ?*Y\": [\"Hi, how do you do?\"],\n",
    "    \"I was ?*X\": [\"Were you really ?X ?\", \"I already knew you were ?X .\"]\n",
    "}\n",
    "def get_response(saying,rules = rules):\n",
    "\tfor pattern in rules.keys():\n",
    "\t\tpat = pat_match_with_seg(pattern.split(),saying.split())\n",
    "\t\tif pat[-1]:\n",
    "\t\t\tresponce_pattern = random.choice(rules[pattern])\n",
    "\t\t\tresponce = substitute(responce_pattern.split(),pat_to_dict(pat))\n",
    "\t\t\treturn ' '.join(responce)\n",
    "\treturn \"sorry, I don't know\"\n",
    "    \n",
    "\n",
    "print(get_response('I was a beautiful and sunny girl'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 中文匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_responses = {\n",
    "    '?*x hello ?*y': ['How do you do', 'Please state your problem'],\n",
    "    '?*x I want ?*y': ['what would it mean if you got ?y', 'Why do you want ?y', 'Suppose you got ?y soon'],\n",
    "    '?*x if ?*y': ['Do you really think its likely that ?y', 'Do you wish that ?y', 'What do you think about ?y', 'Really-- if ?y'],\n",
    "    '?*x no ?*y': ['why not?', 'You are being a negative', 'Are you saying \\'No\\' just to be negative?'],\n",
    "    '?*x I was ?*y': ['Were you really', 'Perhaps I already knew you were ?y', 'Why do you tell me you were ?y now?'],\n",
    "    '?*x I feel ?*y': ['Do you often feel ?y ?', 'What other feelings do you have?'],\n",
    "    '?*x你好?*y': ['你好呀', '请告诉我你的问题'],\n",
    "    '?*x我想?*y': ['你觉得?y有什么意义呢？', '为什么你想?y', '你可以想想你很快就可以?y了'],\n",
    "    '?*x我想要?*y': ['?x想问你，你觉得?y有什么意义呢?', '为什么你想?y', '?x觉得... 你可以想想你很快就可以有?y了', '你看?x像?y不', '我看你就像?y'],\n",
    "    '?*x喜欢?*y': ['喜欢?y的哪里？', '?y有什么好的呢？', '你想要?y吗？'],\n",
    "    '?*x讨厌?*y': ['?y怎么会那么讨厌呢?', '讨厌?y的哪里？', '?y有什么不好呢？', '你不想要?y吗？'],\n",
    "    '?*xAI?*y': ['你为什么要提AI的事情？', '你为什么觉得AI要解决你的问题？'],\n",
    "    '?*x机器人?*y': ['你为什么要提机器人的事情？', '你为什么觉得机器人要解决你的问题？'],\n",
    "    '?*x对不起?*y': ['不用道歉', '你为什么觉得你需要道歉呢?'],\n",
    "    '?*x我记得?*y': ['你经常会想起这个吗？', '除了?y你还会想起什么吗？', '你为什么和我提起?y'],\n",
    "    '?*x如果?*y': ['你真的觉得?y会发生吗？', '你希望?y吗?', '真的吗？如果?y的话', '关于?y你怎么想？'],\n",
    "    '?*x我?*z梦见?*y':['真的吗? --- ?y', '你在醒着的时候，以前想象过?y吗？', '你以前梦见过?y吗'],\n",
    "    '?*x妈妈?*y': ['你家里除了?y还有谁?', '嗯嗯，多说一点和你家里有关系的', '她对你影响很大吗？'],\n",
    "    '?*x爸爸?*y': ['你家里除了?y还有谁?', '嗯嗯，多说一点和你家里有关系的', '他对你影响很大吗？', '每当你想起你爸爸的时候， 你还会想起其他的吗?'],\n",
    "    '?*x我愿意?*y': ['我可以帮你?y吗？', '你可以解释一下，为什么想?y'],\n",
    "    '?*x我很难过，因为?*y': ['我听到你这么说， 也很难过', '?y不应该让你这么难过的'],\n",
    "    '?*x难过?*y': ['我听到你这么说， 也很难过',\n",
    "                 '不应该让你这么难过的，你觉得你拥有什么，就会不难过?',\n",
    "                 '你觉得事情变成什么样，你就不难过了?'],\n",
    "    '?*x就像?*y': ['你觉得?x和?y有什么相似性？', '?x和?y真的有关系吗？', '怎么说？'],\n",
    "    '?*x和?*y都?*z': ['你觉得?z有什么问题吗?', '?z会对你有什么影响呢?'],\n",
    "    '?*x和?*y一样?*z': ['你觉得?z有什么问题吗?', '?z会对你有什么影响呢?'],\n",
    "    '?*x我是?*y': ['真的吗？', '?x想告诉你，或许我早就知道你是?y', '你为什么现在才告诉我你是?y'],\n",
    "    '?*x我是?*y吗': ['如果你是?y会怎么样呢？', '你觉得你是?y吗', '如果你是?y，那一位着什么?'],\n",
    "    '?*x你是?*y吗':  ['你为什么会对我是不是?y感兴趣?', '那你希望我是?y吗', '你要是喜欢， 我就会是?y'],\n",
    "    '?*x你是?*y' : ['为什么你觉得我是?y'],\n",
    "    '?*x因为?*y' : ['?y是真正的原因吗？', '你觉得会有其他原因吗?'],\n",
    "    '?*x我不能?*y': ['你或许现在就能?*y', '如果你能?*y,会怎样呢？'],\n",
    "    '?*x我觉得?*y': ['你经常这样感觉吗？', '除了到这个，你还有什么其他的感觉吗？'],\n",
    "    '?*x我?*y你?*z': ['其实很有可能我们互相?y'],\n",
    "    '?*x你为什么不?*y': ['你自己为什么不?y', '你觉得我不会?y', '等我心情好了，我就?y'],\n",
    "    '?*x好的?*y': ['好的', '你是一个很正能量的人'],\n",
    "    '?*x嗯嗯?*y': ['好的', '你是一个很正能量的人'],\n",
    "    '?*x不嘛?*y': ['为什么不？', '你有一点负能量', '你说 不，是想表达不想的意思吗？'],\n",
    "    '?*x不要?*y': ['为什么不？', '你有一点负能量', '你说 不，是想表达不想的意思吗？'],\n",
    "    '?*x有些人?*y': ['具体是哪些人呢?'],\n",
    "    '?*x有的人?*y': ['具体是哪些人呢?'],\n",
    "    '?*x某些人?*y': ['具体是哪些人呢?'],\n",
    "    '?*x每个人?*y': ['我确定不是人人都是', '你能想到一点特殊情况吗？', '例如谁？', '你看到的其实只是一小部分人'],\n",
    "    '?*x所有人?*y': ['我确定不是人人都是', '你能想到一点特殊情况吗？', '例如谁？', '你看到的其实只是一小部分人'],\n",
    "    '?*x总是?*y': ['你能想到一些其他情况吗?', '例如什么时候?', '你具体是说哪一次？', '真的---总是吗？'],\n",
    "    '?*x一直?*y': ['你能想到一些其他情况吗?', '例如什么时候?', '你具体是说哪一次？', '真的---总是吗？'],\n",
    "    '?*x或许?*y': ['你看起来不太确定'],\n",
    "    '?*x可能?*y': ['你看起来不太确定'],\n",
    "    '?*x他们是?*y吗？': ['你觉得他们可能不是?y？'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "等我心情好了，我就开心\n",
      "Suppose you got an apple soon\n",
      "请继续\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import jieba\n",
    "\n",
    "\n",
    "def is_variable(pat):\n",
    "\treturn pat.startswith('?') and all(s.isalpha() for s in pat[1:])\n",
    "\n",
    "# 判断是否为‘？*‘\n",
    "def is_pattern_segment(pattern):\n",
    "\treturn pattern.startswith('?*') and all(s.isalpha() for s in pattern[2:])\n",
    "\n",
    "def is_match(rest, saying):\n",
    "    if not rest and not saying:\n",
    "        return True\n",
    "    if not all(a.isalpha() for a in rest[0]):\n",
    "        return True\n",
    "    if rest[0] != saying[0]:\n",
    "        return False\n",
    "    return is_match(rest[1:], saying[1:])\n",
    "    \n",
    "def segment_match(pattern,saying):\n",
    "\tseg_pat, rest = pattern[0], pattern[1:]\n",
    "\tseg_pat =seg_pat.replace('?*','?')\n",
    "\n",
    "\tif not rest: \n",
    "\t\treturn (seg_pat, saying),len(saying)\n",
    "\n",
    "\tfor i,token in enumerate(saying):\n",
    "\t\tif rest[0] == token and is_match(rest[1:], saying[(i + 1):]):\n",
    "\t\t\treturn (seg_pat, saying[:i]),i\n",
    "\n",
    "\treturn (seg_pat, None),0\n",
    "\n",
    "\n",
    "fail = [True,None]\n",
    "def pat_match_with_seg(pattern, saying):\n",
    "\tif not pattern or not saying:\n",
    "\t\treturn []\n",
    "\t\n",
    "\tpat = pattern[0]\n",
    "\n",
    "\tif is_variable(pat):\n",
    "\t\treturn [pat, saying[0]] + pat_match_with_seg(pattern[1:],saying[1:])\n",
    "\telif is_pattern_segment(pat):\n",
    "\t\tmatch, index = segment_match(pattern,saying)\n",
    "\t\treturn [match] + pat_match_with_seg(pattern[1:], saying[index:])\n",
    "\telif pat == saying[0]:\n",
    "\t\treturn pat_match_with_seg(pattern[1:],saying[1:])\n",
    "\telse:\n",
    "\t\treturn fail\n",
    "\n",
    "def pat_to_dict(patterns):\n",
    "    return {k: ' '.join(v) if isinstance(v, list) else v for k, v in patterns}\n",
    "\n",
    "def substitute(rule, parsed_rules):\n",
    "    if not rule: return []\n",
    "    \n",
    "    return [parsed_rules.get(rule[0], rule[0])] + substitute(rule[1:], parsed_rules)\n",
    "\n",
    "def get_response(saying,rules = rule_responses):\n",
    "\tfor pattern in rules.keys():\n",
    "\t\tpat = pat_match_with_seg(change_pattern(pattern),change_pattern(saying))\n",
    "\t\tif pat[-1]:\n",
    "\t\t\tresponce_pattern = random.choice(rules[pattern])\n",
    "\t\t\tresponce = substitute(change_pattern(responce_pattern),pat_to_dict(pat))\n",
    "\t\t\t# return ' '.join(responce)\n",
    "\t\t\t\n",
    "\t\t\treturn chinese_blank(' '.join(responce)) \n",
    "\treturn random.choice(['很有趣', '请继续', '我不太确定我很理解你说的, 能稍微详细解释一下吗?'])\n",
    "\n",
    "def repl(matched):\n",
    "\t# 不使用jieba分词\n",
    "\treturn ' '+ matched.group() +' '\n",
    "\t# 使用jieba分词\n",
    "\t# return ' '+ ' '.join(jieba.cut(matched.group())) +' '\n",
    "\n",
    "def change_pattern(pattern):\n",
    "\t# 不使用jieba分词\n",
    "\tpat = re.compile(r'[\\u4e00-\\u9fa5]')\n",
    "\t# 使用jieba分词\n",
    "\t# pat = re.compile(r'[\\u4e00-\\u9fa5]+')\n",
    "\treturn re.sub(pat,repl,pattern).split()\n",
    "\n",
    "def chinese_blank(response):\n",
    "\tpattern = re.compile(u\"[a-zA-Z]+\\s+[a-zA-Z]\")\n",
    "\tentxt = re.findall(pattern,response)\n",
    "\tif (not entxt):\n",
    "\t\tresponse = response.replace(' ','')\n",
    "\treturn response\n",
    "\n",
    "print(get_response('哎，你为什么不开心'))\n",
    "print(get_response('I want an apple'))\n",
    "print(get_response('夸夸我呀'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 思考问题\n",
    "待增补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
